defstar {
	name {Burg}
	domain {SDF}
	version {@(#)SDFBurg.pl	1.24 12/08/97}
	desc {
This star uses Burg's algorithm to estimate the linear predictor coefficients
of an input random process.
These coefficients are produced both in autoregressive form
(on the "lp" output) and in lattice filter form (on the "refl" output).
The "errPower" output is the power of the prediction error as a function
of the predictor order.
	}
	author { E. A. Lee and J. T. Buck }
	copyright {
Copyright (c) 1990-1997 The Regents of the University of California.
All rights reserved.
See the file $PTOLEMY/copyright for copyright notice,
limitation of liability, and disclaimer of warranty provisions.
	}
	location { SDF dsp library }
	htmldoc {
<p>
<a name="Burg's algorithm"></a>
<a name="linear prediction"></a>
<a name="spectral estimation, maximum entropy"></a>
<a name="maximum entropy spectral estimation"></a>
The number of inputs looked at is given by the <i>numInputs</i> parameter
and the order of the autoregressive (AR) model is given by
the <i>order</i> parameter.
<a name="autoregressive model"></a>
<a name="AR model"></a>
The order specifies how many outputs appear on the <i>lp</i> and
<i>refl</i> output portholes.
These outputs are, respectively, the autoregressive (AR) parameters
(also called the linear predictor parameters),
and the reflection coefficients.
<a name="reflection coefficients"></a>
<a name="coefficients, reflection"></a>
<p>
The autoregressive (AR) coefficients are the estimated coefficients of
the all-pole filter that could have produced the observations
(input data) given a white noise input.
The transfer function of the all-pole filter is:
<pre>
              N
             ---
H(z) = 1/(1+ \  d<sub>n</sub>z<sup>-n</sup>)
             /
             ---
             n=1
</pre>
where <i>d</i> is the set of AR coefficients.
<p>
Note that the definition of reflection coefficients is not quite
universal in the literature.
The reflection coefficients in references [2] and [3]
are the negative of the ones generated by this star,
which correspond to the definition in most other texts,
and to the definition of partial-correlation (PARCOR)
coefficients in the statistics literature.
<a name="partial correlation coefficients"></a>
<a name="coefficients, partial correlation"></a>
<a name="PARCOR"></a>
<p>
The <i>errPower</i> output is the power of the prediction error
as a function of the model order.
There are <i>order+</i>1 output samples, and the first sample corresponds
to the prediction error of a zero-th order predictor.
This is simply an estimate of the input signal power.
<a name="Makhoul, J."></a>
<a name="Kay, S. M."></a>
<a name="Haykin, S."></a>
<h3>References</h3>
<p>[1]  
J. Makhoul, "Linear Prediction: A Tutorial Review",
<i>Proc. IEEE</i>, Vol. 63, pp. 561-580, Apr. 1975.
<p>[2]  
S. M. Kay, <i>Modern Spectral Estimation: Theory & Application</i>,
Prentice-Hall, Englewood Cliffs, NJ, 1988.
<p>[3]  
S. Haykin, <i>Modern Filters</i>, MacMillan Publishing Company,
New York, 1989.
	}
	seealso { LevDur, linearPrediction, powerSpectrum }
	input {
		name {input}
		type {float}
		desc { Input random process. }
	}
	output {
		name {lp}
		type {float}
		desc { AR coefficients output. }
	}
	output {
		name {refl}
		type {float}
		desc { Lattice predictor coefficients output. }
	}
	output {
		name {errPower}
		type {float}
		desc { Prediction error power. }
	}
	defstate {
		name {order}
		type {int}
		default {8}
		desc {The number of reflection coefficients to generate.}
	}
	defstate {
		name {numInputs}
		type {int}
		default {64}
		desc { The number of inputs used to estimate the model.}
	}
	protected {
		double *f, *b, *aOrig, *aPrime;
		int N, M;
	}
	constructor {
		f = b = aOrig = aPrime = 0;
		N = M = 0;
	}
	destructor {
		LOG_DEL; delete [] f;
		LOG_DEL; delete [] b;
		LOG_DEL; delete [] aOrig;
		LOG_DEL; delete [] aPrime;
	}
	setup {
		if (N != int(numInputs)) {
			LOG_DEL; delete [] f;
			LOG_DEL; delete [] b;
			N = int(numInputs);
			LOG_NEW; f = new double[N];
			LOG_NEW; b = new double[N];
		}
		if (M != int(order)) {
			LOG_DEL; delete [] aOrig;
			LOG_DEL; delete [] aPrime;
			M = int(order);
			LOG_NEW; aOrig = new double[M+1];
			LOG_NEW; aPrime = new double[M+1];
		}
		refl.setSDFParams (int(order), int(order)-1);
		lp.setSDFParams (int(order), int(order)-1);
		errPower.setSDFParams (int(order)+1, int(order));
		input.setSDFParams (int(numInputs), int(numInputs)-1);
	}
	go {
	    // Define pointers so that the arrays can be swapped
	    double* a = aOrig;
	    double* aP = aPrime;
	    double gamma, dsum, nsum;

	    // initialize the forward and backward predictor errors
	    // and the prediction error power estimate
	    int count = 0;
	    double ep = 0.0;	// error power estimate
	    int i, m;
	    for (i = N-1; i >= 0; i--) {
		double x = input%i;
		f[count] = x;
		b[count++] = x;
		ep += x * x;
	    }
	    ep = ep/N;
	    // output the zeroth order prediction error, which is simply
	    // the power estimate of the input
	    errPower%M << ep;

	    // Iterate on the predictor order
	    for (m = 1; m <= M; m++ ) {
	        // Compute the reflection coefficients, and output them
		nsum = 0.0;
		dsum = 0.0;
		for (i = m; i < N; i++) {
		    nsum += f[i]*b[i-1];
		    dsum += f[i]*f[i] + b[i-1]*b[i-1];
		}
		gamma = -2*nsum/dsum;
		refl%(M-m) << - gamma;

		// update the forward and backward predictor errors
		for (i = N-1; i >= m; i--) {
		    double tempf = f[i];
		    f[i] = tempf + gamma*b[i-1];
		    b[i] = b[i-1] + gamma*tempf;
		}

		// update the prediction error power estimate
		ep = (1 - gamma*gamma) * ep;
		errPower%(M-m) << ep;

		// Update the FIR predictor coefficient estimates
		for (i = 1; i < m; i++) {
		    aP[i] = a[i] + gamma * a[m-i];
		}
		aP[m] = gamma;

		// Swap a and aP for next order recurrence
		double* temp = a;
		a = aP;
		aP = temp;
	    }
	    // generate the lp outputs
	    for (m = 1; m <= M; m++ ) {
		lp%(M-m) << -a[m];
	    }
	}
}
